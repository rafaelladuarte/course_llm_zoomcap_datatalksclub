{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9fc4e2",
   "metadata": {},
   "source": [
    "# Homework: Workshop Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25e3c5",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce21c2",
   "metadata": {},
   "source": [
    "First, we'll define a function that we will use when building our agent.\n",
    "\n",
    "It will generate fake weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98f73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4eef04",
   "metadata": {},
   "source": [
    "## Q1. Define function description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542dc07d",
   "metadata": {},
   "source": [
    "We want to use it as a tool for our agent, so we need to describe it\n",
    "\n",
    "How should the description for this function look like? Fill in missing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe830420",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Document the weather conditions for a particular city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Query the weather data by city\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd1023",
   "metadata": {},
   "source": [
    "What did you put in TODO3?\n",
    "\n",
    "I put `city` in TODO3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce3b326",
   "metadata": {},
   "source": [
    "### Testing it (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f388f65",
   "metadata": {},
   "source": [
    "If you have OpenAI API Key (or alternative provider), let's test it.\n",
    "\n",
    "A question could be \"What's the weather like in Germany?\"\n",
    "\n",
    "Experiment with different system prompts to have better answers from the system.\n",
    "\n",
    "You can use chat_assistant.py or implement everything yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d128287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-15 19:43:59--  https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
      "Resolvendo raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Conectando-se a raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... conectado.\n",
      "A requisiÃ§Ã£o HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 3485 (3,4K) [text/plain]\n",
      "Salvando em: â€˜chat_assistant.py.2â€™\n",
      "\n",
      "chat_assistant.py.2 100%[===================>]   3,40K  --.-KB/s    em 0s      \n",
      "\n",
      "2025-07-15 19:43:59 (12,7 MB/s) - â€˜chat_assistant.py.2â€™ salvo [3485/3485]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0e797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from openai import OpenAI\n",
    "from groq import Groq\n",
    "\n",
    "api_key = os.getenv(\"OGROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chat_assistant\n",
    "import chat_assistant_groq\n",
    "\n",
    "#tools = chat_assistant.Tools()\n",
    "tools = chat_assistant_groq.Tools()\n",
    "tools.add_tool(get_weather, get_weather_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3adbb58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'get_weather',\n",
       "  'description': 'Document the weather conditions for a particular city.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'city': {'type': 'string',\n",
       "     'description': 'Query the weather data by city'}},\n",
       "   'required': ['city'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f011585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai_client = OpenAI(api_key=api_key)\n",
    "groq_client = Groq(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb648f89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_assistant_groq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m developer_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre a course teaching assistant. \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mYou\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre given a question from a course student and your task is to answer it.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mAt the end of each response, ask the user a follow up question based on your answer.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 10\u001b[0m chat_interface \u001b[38;5;241m=\u001b[39m \u001b[43mchat_assistant_groq\u001b[49m\u001b[38;5;241m.\u001b[39mChatInterface()\n\u001b[1;32m     12\u001b[0m chat \u001b[38;5;241m=\u001b[39m chat_assistant_groq\u001b[38;5;241m.\u001b[39mChatAssistant(\n\u001b[1;32m     13\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m     14\u001b[0m     developer_prompt\u001b[38;5;241m=\u001b[39mdeveloper_prompt,\n\u001b[1;32m     15\u001b[0m     chat_interface\u001b[38;5;241m=\u001b[39mchat_interface,\n\u001b[1;32m     16\u001b[0m     client\u001b[38;5;241m=\u001b[39mgroq_client\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chat_assistant_groq' is not defined"
     ]
    }
   ],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant_groq.ChatInterface()\n",
    "\n",
    "chat = chat_assistant_groq.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=groq_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6f768c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Groq' object has no attribute 'responses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/my_github/course_llm_zoomcap_datatalksclub/04_WorkshopAgentAI/chat_assistant.py:109\u001b[0m, in \u001b[0;36mChatAssistant.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m chat_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:  \u001b[38;5;66;03m# inner request loop\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     has_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39moutput:\n",
      "File \u001b[0;32m~/Documentos/my_github/course_llm_zoomcap_datatalksclub/04_WorkshopAgentAI/chat_assistant.py:87\u001b[0m, in \u001b[0;36mChatAssistant.gpt\u001b[0;34m(self, chat_messages)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgpt\u001b[39m(\u001b[38;5;28mself\u001b[39m, chat_messages):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     88\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mchat_messages,\n\u001b[1;32m     90\u001b[0m         tools\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mget_tools(),\n\u001b[1;32m     91\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Groq' object has no attribute 'responses'"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c871b2f",
   "metadata": {},
   "source": [
    "## Q2. Adding another tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca122811",
   "metadata": {},
   "source": [
    "Let's add another tool - a function that can add weather data to our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d62ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weather(city: str, temp: float) -> None:\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c67303",
   "metadata": {},
   "source": [
    "Now let's write a description for it.\n",
    "\n",
    "What did you write?\n",
    "\n",
    "Optionally, you can test it after adding this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047df09a",
   "metadata": {},
   "source": [
    "### MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad6eb64",
   "metadata": {},
   "source": [
    "MCP stands for Model-Context Protocol. It allows LLMs communicate with different tools (like Qdrant). It's function calling, but one step further:\n",
    "\n",
    "A tool can export a list of functions it has\n",
    "When we include the tool to our Agent, we just need to include the link to the MCP server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ca68c",
   "metadata": {},
   "source": [
    "## Q3. Install FastMCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d8360",
   "metadata": {},
   "source": [
    "Let's install a library for MCP - FastMCP:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65337ea",
   "metadata": {},
   "source": [
    "What's the version of FastMCP you installed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed9b38",
   "metadata": {},
   "source": [
    "## Q4. Simple MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1594f29",
   "metadata": {},
   "source": [
    "A simple MCP server from the documentation looks like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa07211",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Already running asyncio in this thread",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mmcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/snap/code/197/.local/share/virtualenvs/course_llm_zoomcap_datatalksclub-mMvewVgg/lib/python3.12/site-packages/fastmcp/server/server.py:328\u001b[0m, in \u001b[0;36mFastMCP.run\u001b[0;34m(self, transport, show_banner, **transport_kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    318\u001b[0m     transport: Transport \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    319\u001b[0m     show_banner: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtransport_kwargs: Any,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the FastMCP server. Note this is a synchronous function.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m        transport: Transport protocol to use (\"stdio\", \"sse\", or \"streamable-http\")\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     \u001b[43manyio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_async\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_banner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_banner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransport_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/snap/code/197/.local/share/virtualenvs/course_llm_zoomcap_datatalksclub-mMvewVgg/lib/python3.12/site-packages/anyio/_core/_eventloop.py:59\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(func, backend, backend_options, *args)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlready running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masynclib_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in this thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     async_backend \u001b[38;5;241m=\u001b[39m get_async_backend(backend)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Already running asyncio in this thread"
     ]
    }
   ],
   "source": [
    "# weather_server.py\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo ðŸš€\")\n",
    "\n",
    "@mcp.tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708094c5",
   "metadata": {},
   "source": [
    "In our case, we need to write docstrings for our functions.\n",
    "\n",
    "Let's ask ChatGPT for help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96865833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieves the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to retrieve weather data.\n",
    "\n",
    "    Returns:\n",
    "        float: The temperature associated with the city.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "\n",
    "def set_weather(city: str, temp: float) -> None:\n",
    "    \"\"\"\n",
    "    Sets the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to set the weather data.\n",
    "        temp (float): The temperature to associate with the city.\n",
    "\n",
    "    Returns:\n",
    "        str: A confirmation string 'OK' indicating successful update.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda05e96",
   "metadata": {},
   "source": [
    "Let's change the example for our case and run it\n",
    "\n",
    "What do you see in the output?\n",
    "\n",
    "Look for a string that matches this template:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f0bef",
   "metadata": {},
   "source": [
    "`Starting MCP server 'Demo ðŸš€' with transport '<TODO>'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c976ed4d",
   "metadata": {},
   "source": [
    "What do you have instead of <TODO>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f88193",
   "metadata": {},
   "source": [
    "## Q5. Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35b68a",
   "metadata": {},
   "source": [
    "There are different ways to communicate with an MCP server. Ours is currently running using standart input/output, which means that the client write something to stdin and read the answer using stdout.\n",
    "\n",
    "Our weather server is currently running.\n",
    "\n",
    "This is how we start communitcating with it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3c680",
   "metadata": {},
   "source": [
    "* First, we send an initialization request -- this way, we register our client with the server:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}, \"sampling\": {}}, \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}}}\n",
    "```\n",
    "* We should get back something like that, which is an aknowledgement of the request:\n",
    "```json\n",
    "{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":false},\"resources\":{\"subscribe\":false,\"listChanged\":false},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"Demo ðŸš€\",\"version\":\"1.9.4\"}}}\n",
    "```\n",
    "* Next, we reply back, confirming the initialization:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"}\n",
    "```\n",
    "We don't expect to get anything in response\n",
    "* Now we can ask for a list of available methods:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/list\"}\n",
    "```\n",
    "* Let's ask the temperature in Berlin:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"<TODO>\", \"arguments\": {<TODO>}}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a1af5",
   "metadata": {},
   "source": [
    "What did you get in response?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ac5cb",
   "metadata": {},
   "source": [
    "## Q6. Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096d47c",
   "metadata": {},
   "source": [
    "We typically don't interact with the server by copy-pasting commands in the terminal.\n",
    "\n",
    "In practice, we use an MCP Client. Let's implement it.\n",
    "\n",
    "FastMCP also supports MCP clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89bfb227",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2621171520.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    async with Client(<TODO>) as mcp_client:\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "async def main():\n",
    "    async with Client(<TODO>) as mcp_client:\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004cf13",
   "metadata": {},
   "source": [
    "Use the client to get the list of available tools of our script. How does the result look like?\n",
    "\n",
    "If you're running this code in Jupyter, you need to pass an instance of MCP server to the Client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weather_server\n",
    "\n",
    "async def main():\n",
    "    async with Client(weather_server.mcp) as mcp_client:\n",
    "        # ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5e610",
   "metadata": {},
   "source": [
    "If you run it in a script, you will need to use asyncio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b405ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async with Client(\"weather_server.py\") as mcp_client:\n",
    "        # ...\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af19e4c",
   "metadata": {},
   "source": [
    "Copy the output with the available tools when filling in the homework form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d772c03",
   "metadata": {},
   "source": [
    "### Using tools from the MCP server (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3862f1",
   "metadata": {},
   "source": [
    "FastMCP uses asyncio for client-server communication. In our case, the code we wrote previously in the module (chat_assistant.py) is not asyncio-friendly, so it will require a lot of adjustments to run it.\n",
    "\n",
    "Which is why we asked Claude to implement a simple non-async MCP client (see mcp_client.py) that can only do this:\n",
    "\n",
    "List tools\n",
    "Invoke the specified tool\n",
    "Note: this is not a production-ready MCP Client! Use it only for learning purposes.\n",
    "\n",
    "Check the code - it's quite illustrative. Or experiment with writing this code yourself.\n",
    "\n",
    "Here's how we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b3d0732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python weather_server.py\n",
      "Sending initialize request...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No response from server",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m our_mcp_client \u001b[38;5;241m=\u001b[39m mcp_client\u001b[38;5;241m.\u001b[39mMCPClient([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather_server.py\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m our_mcp_client\u001b[38;5;241m.\u001b[39mstart_server()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mour_mcp_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m our_mcp_client\u001b[38;5;241m.\u001b[39minitialized()\n",
      "File \u001b[0;32m~/Documentos/my_github/course_llm_zoomcap_datatalksclub/04_WorkshopAgentAI/mcp_client.py:98\u001b[0m, in \u001b[0;36mMCPClient.initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send initialize request to the server\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending initialize request...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minitialize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotocolVersion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2024-11-05\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapabilities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroots\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlistChanged\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclientInfo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest-client\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialize response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documentos/my_github/course_llm_zoomcap_datatalksclub/04_WorkshopAgentAI/mcp_client.py:85\u001b[0m, in \u001b[0;36mMCPClient._send_request\u001b[0;34m(self, method, params)\u001b[0m\n\u001b[1;32m     83\u001b[0m response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response_str:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo response from server\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response_str)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No response from server"
     ]
    }
   ],
   "source": [
    "import mcp_client\n",
    "\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ed496",
   "metadata": {},
   "source": [
    "While it's somewhat verbose, it follows the initialization structure we outlined in Q5.\n",
    "\n",
    "Now we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e162c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_mcp_client.get_tools()\n",
    "our_mcp_client.call_tool('get_weather', {'city': 'Berlin'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258dcb5",
   "metadata": {},
   "source": [
    "In order to include it in our existing application, we need a wrapper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d260e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class MCPTools:\n",
    "    def __init__(self, mcp_client):\n",
    "        self.mcp_client = mcp_client\n",
    "        self.tools = None\n",
    "    \n",
    "    def get_tools(self):\n",
    "        if self.tools is None:\n",
    "            mcp_tools = self.mcp_client.get_tools()\n",
    "            self.tools = convert_tools_list(mcp_tools)\n",
    "        return self.tools\n",
    "\n",
    "    def function_call(self, tool_call_response):\n",
    "        function_name = tool_call_response.name\n",
    "        arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "        result = self.mcp_client.call_tool(function_name, arguments)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call_response.call_id,\n",
    "            \"output\": json.dumps(result, indent=2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e844cf9",
   "metadata": {},
   "source": [
    "It's very similar to the Tools class we created in the module, but it uses MCP to communicate with the MCP Server.\n",
    "\n",
    "(Where convert_tools_list converts MCP functions description format into the OpenAI's one)\n",
    "\n",
    "Let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You help users find out the weather in their cities. \n",
    "If they didn't specify a city, ask them. Make sure we always use a city.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb52bb",
   "metadata": {},
   "source": [
    "Now we use the MCP server for function calling!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_llm_zoomcap_datatalksclub-mMvewVgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
