{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9fc4e2",
   "metadata": {},
   "source": [
    "# Homework: Workshop Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25e3c5",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce21c2",
   "metadata": {},
   "source": [
    "First, we'll define a function that we will use when building our agent.\n",
    "\n",
    "It will generate fake weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98f73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4eef04",
   "metadata": {},
   "source": [
    "## Q1. Define function description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542dc07d",
   "metadata": {},
   "source": [
    "We want to use it as a tool for our agent, so we need to describe it\n",
    "\n",
    "How should the description for this function look like? Fill in missing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe830420",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"<TODO1>\",\n",
    "    \"description\": \"<TODO2>\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"<TODO3>\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"<TODO4>\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"<TODO5>\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd1023",
   "metadata": {},
   "source": [
    "What did you put in TODO3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce3b326",
   "metadata": {},
   "source": [
    "### Testing it (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f388f65",
   "metadata": {},
   "source": [
    "If you have OpenAI API Key (or alternative provider), let's test it.\n",
    "\n",
    "A question could be \"What's the weather like in Germany?\"\n",
    "\n",
    "Experiment with different system prompts to have better answers from the system.\n",
    "\n",
    "You can use chat_assistant.py or implement everything yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d128287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c871b2f",
   "metadata": {},
   "source": [
    "## Q2. Adding another tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca122811",
   "metadata": {},
   "source": [
    "Let's add another tool - a function that can add weather data to our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d62ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weather(city: str, temp: float) -> None:\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c67303",
   "metadata": {},
   "source": [
    "Now let's write a description for it.\n",
    "\n",
    "What did you write?\n",
    "\n",
    "Optionally, you can test it after adding this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047df09a",
   "metadata": {},
   "source": [
    "### MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad6eb64",
   "metadata": {},
   "source": [
    "MCP stands for Model-Context Protocol. It allows LLMs communicate with different tools (like Qdrant). It's function calling, but one step further:\n",
    "\n",
    "A tool can export a list of functions it has\n",
    "When we include the tool to our Agent, we just need to include the link to the MCP server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ca68c",
   "metadata": {},
   "source": [
    "## Q3. Install FastMCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d8360",
   "metadata": {},
   "source": [
    "Let's install a library for MCP - FastMCP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe9413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLoading .env environment variables\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[32mCourtesy Notice\u001b[0m:\n",
      "Pipenv found itself running within a virtual environment,  so it will \n",
      "automatically use that environment, instead of  creating its own for any \n",
      "project. You can set\n",
      "\u001b[1;33mPIPENV_IGNORE_VIRTUALENVS\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m1\u001b[0m to force pipenv to ignore that environment and \n",
      "create  its own instead.\n",
      "You can set \u001b[1;33mPIPENV_VERBOSITY\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m-1\u001b[0m to suppress this warning.\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1;32mInstalling fastmcp...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(226ace)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1;32mUpgrading\u001b[0m fastmcp in \u001b[39m dependencies.\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m Locking packages..."
     ]
    }
   ],
   "source": [
    "!pipenv install fastmcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65337ea",
   "metadata": {},
   "source": [
    "What's the version of FastMCP you installed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed9b38",
   "metadata": {},
   "source": [
    "## Q4. Simple MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1594f29",
   "metadata": {},
   "source": [
    "A simple MCP server from the documentation looks like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa07211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_server.py\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo 🚀\")\n",
    "\n",
    "@mcp.tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708094c5",
   "metadata": {},
   "source": [
    "In our case, we need to write docstrings for our functions.\n",
    "\n",
    "Let's ask ChatGPT for help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96865833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieves the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to retrieve weather data.\n",
    "\n",
    "    Returns:\n",
    "        float: The temperature associated with the city.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "\n",
    "def set_weather(city: str, temp: float) -> None:\n",
    "    \"\"\"\n",
    "    Sets the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to set the weather data.\n",
    "        temp (float): The temperature to associate with the city.\n",
    "\n",
    "    Returns:\n",
    "        str: A confirmation string 'OK' indicating successful update.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda05e96",
   "metadata": {},
   "source": [
    "Let's change the example for our case and run it\n",
    "\n",
    "What do you see in the output?\n",
    "\n",
    "Look for a string that matches this template:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f0bef",
   "metadata": {},
   "source": [
    "`Starting MCP server 'Demo 🚀' with transport '<TODO>'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c976ed4d",
   "metadata": {},
   "source": [
    "What do you have instead of <TODO>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f88193",
   "metadata": {},
   "source": [
    "## Q5. Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35b68a",
   "metadata": {},
   "source": [
    "There are different ways to communicate with an MCP server. Ours is currently running using standart input/output, which means that the client write something to stdin and read the answer using stdout.\n",
    "\n",
    "Our weather server is currently running.\n",
    "\n",
    "This is how we start communitcating with it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3c680",
   "metadata": {},
   "source": [
    "* First, we send an initialization request -- this way, we register our client with the server:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}, \"sampling\": {}}, \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}}}\n",
    "```\n",
    "* We should get back something like that, which is an aknowledgement of the request:\n",
    "```json\n",
    "{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":false},\"resources\":{\"subscribe\":false,\"listChanged\":false},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"Demo 🚀\",\"version\":\"1.9.4\"}}}\n",
    "```\n",
    "* Next, we reply back, confirming the initialization:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"}\n",
    "```\n",
    "We don't expect to get anything in response\n",
    "* Now we can ask for a list of available methods:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/list\"}\n",
    "```\n",
    "* Let's ask the temperature in Berlin:\n",
    "```json\n",
    "{\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"<TODO>\", \"arguments\": {<TODO>}}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a1af5",
   "metadata": {},
   "source": [
    "What did you get in response?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ac5cb",
   "metadata": {},
   "source": [
    "## Q6. Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096d47c",
   "metadata": {},
   "source": [
    "We typically don't interact with the server by copy-pasting commands in the terminal.\n",
    "\n",
    "In practice, we use an MCP Client. Let's implement it.\n",
    "\n",
    "FastMCP also supports MCP clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "async def main():\n",
    "    async with Client(<TODO>) as mcp_client:\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004cf13",
   "metadata": {},
   "source": [
    "Use the client to get the list of available tools of our script. How does the result look like?\n",
    "\n",
    "If you're running this code in Jupyter, you need to pass an instance of MCP server to the Client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weather_server\n",
    "\n",
    "async def main():\n",
    "    async with Client(weather_server.mcp) as mcp_client:\n",
    "        # ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5e610",
   "metadata": {},
   "source": [
    "If you run it in a script, you will need to use asyncio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b405ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async with Client(\"weather_server.py\") as mcp_client:\n",
    "        # ...\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af19e4c",
   "metadata": {},
   "source": [
    "Copy the output with the available tools when filling in the homework form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d772c03",
   "metadata": {},
   "source": [
    "### Using tools from the MCP server (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3862f1",
   "metadata": {},
   "source": [
    "FastMCP uses asyncio for client-server communication. In our case, the code we wrote previously in the module (chat_assistant.py) is not asyncio-friendly, so it will require a lot of adjustments to run it.\n",
    "\n",
    "Which is why we asked Claude to implement a simple non-async MCP client (see mcp_client.py) that can only do this:\n",
    "\n",
    "List tools\n",
    "Invoke the specified tool\n",
    "Note: this is not a production-ready MCP Client! Use it only for learning purposes.\n",
    "\n",
    "Check the code - it's quite illustrative. Or experiment with writing this code yourself.\n",
    "\n",
    "Here's how we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcp_client\n",
    "\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ed496",
   "metadata": {},
   "source": [
    "While it's somewhat verbose, it follows the initialization structure we outlined in Q5.\n",
    "\n",
    "Now we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e162c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_mcp_client.get_tools()\n",
    "our_mcp_client.call_tool('get_weather', {'city': 'Berlin'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258dcb5",
   "metadata": {},
   "source": [
    "In order to include it in our existing application, we need a wrapper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d260e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class MCPTools:\n",
    "    def __init__(self, mcp_client):\n",
    "        self.mcp_client = mcp_client\n",
    "        self.tools = None\n",
    "    \n",
    "    def get_tools(self):\n",
    "        if self.tools is None:\n",
    "            mcp_tools = self.mcp_client.get_tools()\n",
    "            self.tools = convert_tools_list(mcp_tools)\n",
    "        return self.tools\n",
    "\n",
    "    def function_call(self, tool_call_response):\n",
    "        function_name = tool_call_response.name\n",
    "        arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "        result = self.mcp_client.call_tool(function_name, arguments)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call_response.call_id,\n",
    "            \"output\": json.dumps(result, indent=2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e844cf9",
   "metadata": {},
   "source": [
    "It's very similar to the Tools class we created in the module, but it uses MCP to communicate with the MCP Server.\n",
    "\n",
    "(Where convert_tools_list converts MCP functions description format into the OpenAI's one)\n",
    "\n",
    "Let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You help users find out the weather in their cities. \n",
    "If they didn't specify a city, ask them. Make sure we always use a city.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb52bb",
   "metadata": {},
   "source": [
    "Now we use the MCP server for function calling!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_llm_zoomcap_datatalksclub-mMvewVgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
